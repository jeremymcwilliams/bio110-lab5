
---
title: "Bio 110 Lab 5"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---


# Lab 5 - Using Digital Microscopy to measure Chlamydomonas flagella

**IMPORTANT** As a general rule of coding, when trying out new code, NEVER directly edit the example code.  ALWAYS copy and paste and then edit the copied code to ensure that the example code is not altered or accidentally deleted.

The goals of this tutorial are to:
* import your data in a spreadsheet to R Studio
* calculate the mean of your measured flagella lengths at each time point
* calculate the 95% confidence intervals of the mean flagella length at each time point
* plot the means as points with error bars on a graph

Now that you have collected measurements for 15 Chlamydomonas flagella per time point, you must import your spreadsheet of data to R Studio. The format of the columns of data is important, as well as the titles of the columns of data. 

You should have two columns of data titled, time and length, with no extra columns or unusual characters.

Once you have checked that your spreadsheet follows these basic rules, save it as a .csv file in your BIO 110 folder on the desktop. The file should have a short simple name, such as your group's initials. 

First you must upload your .csv file to R Studio in the bottom right window using the Upload button.  Browse to locate your file and click Upload.  Make sure it's loaded into the bio110-week4 folder.

Before writing any R code, we'll need to load some R packages in order to use some of the specific functions we want.  Run the code chunk below to make sure these functions are available to your environment:

```{r}

# the "tidyverse" loads multiple packages that we need, like ggplot, dplyr, and readr

library(tidyverse)



```
 

Just like last week, you'll want to load your data as a data frame into R by assigning it to a variable. 

Load your data file to a variable called myData using the read_csv() function, and print your variable to confirm:

```{r}
# for example,copy and paste the following command below, using your .csv file name in "":
# myData<-read_csv("myData.csv")

treated<-read_csv("treated.csv")

untreated<-read_csv("untreated.csv")



# confirm by printing your variable

treated
untreated

```


Our end goal is to plot the mean of each measurement with 95% confidence interval bars, grouped by each time interval (e.g. all the measurements at 25, 40, 55, etc.). As such we're going to use some new coding strategies to get our data in the form we want. 

One common approach to this is to use the "group_by" function in tandem with the "summarise" function. Furthermore, we're going to use the R "pipe" operator %>%, which is used to pass data to new functions. Here's an example command:

myStats<-myData %>% group_by(time) %>% summarise (Average=mean(length), StandardDeviation=sd(length), n=n())

Let's analyze what's happening here to create the new data frame myStats

1) I'm starting with my loaded data (myData)

2) I'm using the %>% command to pass myData to the group_by function, and indicating that the data should be grouped by the "time" column header.

3) Then, I'm "piping" this to the "summarise" function, which lets me create columns in my new data frame "myStats" based upon formulas. In this case, I'm creating a column called "Average" and setting it equal to the mean of the grouped "length" column from myData. I'm also creating the column "StandardDeviation", and setting it equal to the standard deviation of the grouped data, using the sd() function. Finally I'm creating the column "n", which uses the n() function to count the number of measurements in each group.

So the new "myStats" data frame should have a structure that looks like this (the #'s are just placeholders for real computed values):

time, Average, StandardDeviation, n
25, #, #, #
40, #, #, #
55, #, #, #
70, #, #, #
85, #, #, #

This new data frame structured this way is the precursor for creating the plot that we want that shows the differences in groups.

Go ahead and try the group_by/summarise technique with your data, by copying and pasting the code in line 64 to line 89, then run the code block. You may need to edit the code if your column titles do not exactly match, time and length.

```{r}
# create a new data frame variable, adding columns for mean, standard deviation, and number of measurements 

treatedStats<-treated %>% group_by(time) %>% summarise (Average=mean(length), StandardDeviation=sd(length), n=n())

untreatedStats<-untreated %>% group_by(time) %>% summarise (Average=mean(length), StandardDeviation=sd(length), n=n())
# print the variable to check your success
treatedStats
untreatedStats

```


The grouped data frame we just created is pretty good, but we need to add the upper and lower limits of the 95% confidence interval for our plot error bars. Here's the formula for computing upper- and lower- confidence interval values:

upperCI<-Average+((qnorm(0.975)*StandardDeviation)/sqrt(n))

lowerCI<-Average-((qnorm(0.975)*StandardDeviation)/sqrt(n))

In the formulas above, Average, StandardDeviation, and n are all variables that could be calculated in the "summarise" function used earlier. In the code block below, try updating your group_by/summarise code from earlier to add lowerCI and upperCI:




```{r}

# create a new data frame variable, adding columns for mean, standard deviation, number of measurements, upperCI, and lowerCI

treatedStats<-treated %>% group_by(time) %>% summarise (Average=mean(length), StandardDeviation=sd(length), n=n(), upperCI=Average+((qnorm(0.975)*StandardDeviation)/sqrt(n)), lowerCI=Average-((qnorm(0.975)*StandardDeviation)/sqrt(n)))

untreatedStats<-untreated %>% group_by(time) %>% summarise (Average=mean(length), StandardDeviation=sd(length), n=n(), upperCI=Average+((qnorm(0.975)*StandardDeviation)/sqrt(n)), lowerCI=Average-((qnorm(0.975)*StandardDeviation)/sqrt(n)))


# print the variable to check your success

treatedStats
untreatedStats



```




Now with the data in this format, we should be able to create a visualization. Here are the characteristics we want:

* a point plotted for each group
* Time on the x-axis
* Average length on the y-axis
* Error bars for each point, showing the 95% confidence interval
* A line through each point


The best way to approach this is to try a little bit at a time, test the output, add a little more, and test again, etc.

To start, try just generating a plot with points. You'll want to use ggplot, with this general format:


ggplot(data=myStats, mapping=aes(x=time, y=Average))+geom_point()

...where myStats is your new data set (after running the groub_by/summarise code), time is your column header for the time group, and Average is the column header for the mean.


```{r}

# Generate a point plot of your data below, with time on the x-axis, and average on the y-axis, using geom_point()
 ggplot()+geom_point(data=treatedStats, mapping=aes(x=time, y=Average))+geom_point(data=untreatedStats, mapping=aes(x=time, y=Average))




```


Now add the error bars, using geom_error(). Your ymin and ymax values should be your calculated lower and upper 95% confidence interval values, respectively:

```{r}

# Generate your plot with geom_point(), and add error bars using geom_errorbar() 


 ggplot()+geom_point(data=treatedStats, mapping=aes(x=time, y=Average), shape = 15, color = "black", size=5)+
  geom_errorbar(data=treatedStats, mapping=aes(x=time, ymin=lowerCI, ymax=upperCI), width=5)+
  geom_point(data=untreatedStats, mapping=aes(x=time, y=Average), shape=17, color="grey", size=5)+
  geom_errorbar(data=untreatedStats, mapping=aes(x=time, ymin=lowerCI, ymax=upperCI), width=5)




```


Now let's add the line connecting the dots using geom_path(). We can do this by appending  +geom_path(mapping=aes(x=time, y=Average)). 

```{r}

# Add the line to the graph:
# ggplot(data=myStats, mapping=aes(x=time,y=Average))+geom_point()+geom_errorbar(mapping=aes(ymin=lowerCI, ymax=upperCI), width=5)+geom_path(mapping=aes(x=time, y=Average))

 ggplot()+geom_point(data=treatedStats, mapping=aes(x=time, y=Average), shape = 15, color = "black", size=5)+
  geom_errorbar(data=treatedStats, mapping=aes(x=time, ymin=lowerCI, ymax=upperCI), width=5)+
  geom_path(data=treatedStats, mapping=aes(x=time, y=Average))+
  geom_point(data=untreatedStats, mapping=aes(x=time, y=Average), shape=17, color="grey", size=5)+
  geom_errorbar(data=untreatedStats, mapping=aes(x=time, ymin=lowerCI, ymax=upperCI), width=5, color="grey")+
  geom_path(data=untreatedStats, mapping=aes(x=time, y=Average), color="grey")

```


Now we can clean up the plot by adjusting our x- and y- axes with the xlim() and ylim() functions. Each function takes a minimum and maximum (e.g. +ylim(0, 10)).  Make sure your upper limit is high enough to include all data points and error bars.

```{r}

# Adjust your axes with the xlim and ylim functions. Edit the values those functions below to improve your plot.

# ggplot(data=myStats, mapping=aes(x=time,y=Average))+geom_point()+geom_errorbar(mapping=aes(ymin=lowerCI, ymax=upperCI), width=5)+geom_path(mapping=aes(x=time,y=Average))+xlim(0,100)+ylim(0,10)





```


Finally, add some labels using the labs() function:

```{r}

# Update the values in the labs() function below (and others as appropriate)

#cut and paste your previous code and add: +labs(x="my x label", y="my y axis label") filling in the appropriate labels for your axes


```





Make sure you copy and save your plot and print it with a detailed caption to turn in to your instructor.
